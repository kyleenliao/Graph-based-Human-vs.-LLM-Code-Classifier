{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network for Human vs LLM Code Classification\n",
    "\n",
    "This notebook implements a GIN (Graph Isomorphism Network) to distinguish between human-written and LLM-generated Python code using Abstract Syntax Tree (AST) representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, roc_auc_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import custom modules\n",
    "from graphdataset import CodeGraphDataset\n",
    "from process import PythonCodeProcessor\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Max nodes: 500\n",
      "  Embedding size: 128\n",
      "  Batch size: 32\n",
      "  Learning rate: 0.001\n",
      "  Epochs: 50\n",
      "  Hidden dim: 256\n",
      "  GIN layers: 5\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_DIR = 'CS22W_dataset/python'\n",
    "VALID_FILE = os.path.join(DATA_DIR, 'valid_no_comment.jsonl')\n",
    "TEST_FILE = os.path.join(DATA_DIR, 'test_no_comment.jsonl')\n",
    "\n",
    "MAX_NODES = 500  # Maximum nodes in AST\n",
    "EMBEDDING_SIZE = 128  # Dimension of node embeddings\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 5\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Max nodes: {MAX_NODES}\")\n",
    "print(f\"  Embedding size: {EMBEDDING_SIZE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  GIN layers: {NUM_LAYERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation dataset...\n",
      "Processing graphs from CS22W_dataset/python/valid_no_comment.jsonl\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CS22W_dataset/python/valid_no_comment.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading validation dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m valid_dataset = \u001b[43mCodeGraphDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjsonl_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVALID_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_NODES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEMBEDDING_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_reprocess\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLoading test dataset (sharing vocabulary)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m test_dataset = CodeGraphDataset(\n\u001b[32m     12\u001b[39m     jsonl_path=TEST_FILE,\n\u001b[32m     13\u001b[39m     processor=valid_dataset.processor,  \u001b[38;5;66;03m# Share vocabulary\u001b[39;00m\n\u001b[32m     14\u001b[39m     max_nodes=MAX_NODES\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS224W/Graph-based-Human-vs.-LLM-Code-Classifier/graphdataset.py:65\u001b[39m, in \u001b[36mCodeGraphDataset.__init__\u001b[39m\u001b[34m(self, jsonl_path, processor, cache_dir, force_reprocess, max_nodes, embedding_size)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing graphs from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjsonl_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_and_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS224W/Graph-based-Human-vs.-LLM-Code-Classifier/graphdataset.py:77\u001b[39m, in \u001b[36mCodeGraphDataset._process_and_cache\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_and_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     76\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Process all code samples and cache results.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     raw_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;66;03m# Train embedding if needed\u001b[39;00m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.needs_embedding:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS224W/Graph-based-Human-vs.-LLM-Code-Classifier/graphdataset.py:69\u001b[39m, in \u001b[36mCodeGraphDataset._load_raw_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load_raw_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     68\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load raw JSONL data.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjsonl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     70\u001b[39m         lines = f.readlines()\n\u001b[32m     71\u001b[39m     data = [json.loads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'CS22W_dataset/python/valid_no_comment.jsonl'"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"Loading validation dataset...\")\n",
    "valid_dataset = CodeGraphDataset(\n",
    "    jsonl_path=VALID_FILE,\n",
    "    max_nodes=MAX_NODES,\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    force_reprocess=False\n",
    ")\n",
    "\n",
    "print(\"\\nLoading test dataset (sharing vocabulary)...\")\n",
    "test_dataset = CodeGraphDataset(\n",
    "    jsonl_path=TEST_FILE,\n",
    "    processor=valid_dataset.processor,  # Share vocabulary\n",
    "    max_nodes=MAX_NODES\n",
    ")\n",
    "\n",
    "print(f\"\\nValidation set size: {len(valid_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION DATASET STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "valid_stats = valid_dataset.get_stats()\n",
    "for key, value in valid_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST DATASET STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "test_stats = test_dataset.get_stats()\n",
    "for key, value in test_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Validation set\n",
    "valid_labels = valid_stats['label_distribution']\n",
    "axes[0].bar(valid_labels.keys(), valid_labels.values(), color=['#3498db', '#e74c3c'])\n",
    "axes[0].set_title('Validation Set Label Distribution')\n",
    "axes[0].set_xlabel('Label (0=Human, 1=LLM)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Test set\n",
    "test_labels = test_stats['label_distribution']\n",
    "axes[1].bar(test_labels.keys(), test_labels.values(), color=['#3498db', '#e74c3c'])\n",
    "axes[1].set_title('Test Set Label Distribution')\n",
    "axes[1].set_xlabel('Label (0=Human, 1=LLM)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('label_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a sample\n",
    "sample = valid_dataset[0]\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE DATA POINT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Index: {sample['index']}\")\n",
    "print(f\"Label: {sample['label'].item()} ({'Human' if sample['label'].item() == 0 else 'LLM'})\")\n",
    "print(f\"\\nCode Graph:\")\n",
    "print(f\"  Shape: {sample['code_graph'].shape}\")\n",
    "print(f\"  Number of nodes: {sample['code_num_nodes']}\")\n",
    "print(f\"  Sequence length: {len(sample['code_sequence'])}\")\n",
    "print(f\"  First 15 tokens: {sample['code_sequence'][:15]}\")\n",
    "print(f\"\\nContrast Graph:\")\n",
    "print(f\"  Shape: {sample['contrast_graph'].shape}\")\n",
    "print(f\"  Number of nodes: {sample['contrast_num_nodes']}\")\n",
    "print(f\"  Sequence length: {len(sample['contrast_sequence'])}\")\n",
    "print(f\"  First 15 tokens: {sample['contrast_sequence'][:15]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embedding matrix\n",
    "embedding_matrix = valid_dataset.get_embedding_matrix()\n",
    "print(f\"\\nEmbedding matrix shape: {embedding_matrix.shape}\")\n",
    "print(f\"Vocabulary size: {embedding_matrix.shape[0] - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GIN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINLayer(nn.Module):\n",
    "    \"\"\"Graph Isomorphism Network Layer.\n",
    "    \n",
    "    Implements: h_v^(k) = MLP^(k)((1 + epsilon^(k)) * h_v^(k-1) + sum_{u in N(v)} h_u^(k-1))\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, eps_learnable=True):\n",
    "        super(GINLayer, self).__init__()\n",
    "        \n",
    "        # MLP for node update\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Learnable epsilon parameter\n",
    "        if eps_learnable:\n",
    "            self.eps = nn.Parameter(torch.zeros(1))\n",
    "        else:\n",
    "            self.register_buffer('eps', torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Node features [batch_size, num_nodes, feature_dim]\n",
    "            adj: Adjacency matrix [batch_size, num_nodes, num_nodes]\n",
    "        \n",
    "        Returns:\n",
    "            Updated node features [batch_size, num_nodes, output_dim]\n",
    "        \"\"\"\n",
    "        # Aggregate neighbor features: sum_{u in N(v)} h_u\n",
    "        # adj[b, i, j] = 1 if edge from i to j\n",
    "        neighbor_sum = torch.bmm(adj, x)  # [batch_size, num_nodes, feature_dim]\n",
    "        \n",
    "        # Remove self-loop from aggregation (we'll add it back with epsilon)\n",
    "        # Create diagonal mask\n",
    "        eye = torch.eye(adj.size(1), device=adj.device).unsqueeze(0)  # [1, num_nodes, num_nodes]\n",
    "        self_features = torch.bmm(eye, x)  # [batch_size, num_nodes, feature_dim]\n",
    "        neighbor_sum = neighbor_sum - self_features\n",
    "        \n",
    "        # Apply GIN update rule\n",
    "        out = (1 + self.eps) * x + neighbor_sum\n",
    "        \n",
    "        # Apply MLP\n",
    "        batch_size, num_nodes, feature_dim = out.size()\n",
    "        out = out.view(batch_size * num_nodes, feature_dim)\n",
    "        out = self.mlp(out)\n",
    "        out = out.view(batch_size, num_nodes, -1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class GINNetwork(nn.Module):\n",
    "    \"\"\"Graph Isomorphism Network for code classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, \n",
    "                 num_classes=2, dropout=0.3, pretrained_embeddings=None):\n",
    "        super(GINNetwork, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Token embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            # Optionally freeze embeddings\n",
    "            # self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        # GIN layers\n",
    "        self.gin_layers = nn.ModuleList()\n",
    "        \n",
    "        # First layer\n",
    "        self.gin_layers.append(\n",
    "            GINLayer(embedding_dim, hidden_dim, hidden_dim, eps_learnable=True)\n",
    "        )\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.gin_layers.append(\n",
    "                GINLayer(hidden_dim, hidden_dim, hidden_dim, eps_learnable=True)\n",
    "            )\n",
    "        \n",
    "        # Readout MLP (for graph-level classification)\n",
    "        self.readout = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * num_layers, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sequences, adj_matrices, num_nodes_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequences: Token sequences [batch_size, max_seq_len]\n",
    "            adj_matrices: Adjacency matrices [batch_size, max_nodes, max_nodes]\n",
    "            num_nodes_list: Actual number of nodes for each graph [batch_size]\n",
    "        \n",
    "        Returns:\n",
    "            logits: [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        batch_size = adj_matrices.size(0)\n",
    "        max_nodes = adj_matrices.size(1)\n",
    "        \n",
    "        # Convert sequences to embeddings\n",
    "        # Pad/truncate sequences to max_nodes\n",
    "        if sequences[0].size(0) > max_nodes:\n",
    "            # Truncate\n",
    "            node_features = torch.stack([seq[:max_nodes] for seq in sequences])\n",
    "        else:\n",
    "            # Pad\n",
    "            node_features = torch.zeros(batch_size, max_nodes, dtype=torch.long, device=adj_matrices.device)\n",
    "            for i, seq in enumerate(sequences):\n",
    "                seq_len = min(len(seq), max_nodes)\n",
    "                node_features[i, :seq_len] = torch.tensor(seq[:seq_len], dtype=torch.long, device=adj_matrices.device)\n",
    "        \n",
    "        # Embed tokens\n",
    "        x = self.embedding(node_features)  # [batch_size, max_nodes, embedding_dim]\n",
    "        \n",
    "        # Apply GIN layers and collect representations\n",
    "        layer_outputs = []\n",
    "        \n",
    "        for layer in self.gin_layers:\n",
    "            x = layer(x, adj_matrices)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            layer_outputs.append(x)\n",
    "        \n",
    "        # Graph-level readout: sum pooling with masking\n",
    "        graph_representations = []\n",
    "        \n",
    "        for layer_out in layer_outputs:\n",
    "            # Create mask for valid nodes\n",
    "            mask = torch.zeros(batch_size, max_nodes, 1, device=layer_out.device)\n",
    "            for i, num_nodes in enumerate(num_nodes_list):\n",
    "                mask[i, :num_nodes, :] = 1.0\n",
    "            \n",
    "            # Masked sum pooling\n",
    "            masked_out = layer_out * mask\n",
    "            graph_rep = masked_out.sum(dim=1)  # [batch_size, hidden_dim]\n",
    "            graph_representations.append(graph_rep)\n",
    "        \n",
    "        # Concatenate all layer outputs\n",
    "        graph_rep = torch.cat(graph_representations, dim=1)  # [batch_size, hidden_dim * num_layers]\n",
    "        \n",
    "        # Final classification\n",
    "        logits = self.readout(graph_rep)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class SiameseGNN(nn.Module):\n",
    "    \"\"\"Siamese network for comparing code and contrast samples.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
    "                 num_classes=2, dropout=0.3, pretrained_embeddings=None):\n",
    "        super(SiameseGNN, self).__init__()\n",
    "        \n",
    "        # Shared GNN encoder\n",
    "        self.gnn = GINNetwork(\n",
    "            vocab_size=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            num_classes=hidden_dim * num_layers,  # Output embedding instead of class\n",
    "            dropout=dropout,\n",
    "            pretrained_embeddings=pretrained_embeddings\n",
    "        )\n",
    "        \n",
    "        # Classifier on combined representations\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * num_layers * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, code_seq, code_adj, code_num_nodes,\n",
    "                contrast_seq, contrast_adj, contrast_num_nodes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            code_seq: Token sequences for code [batch_size, max_seq_len]\n",
    "            code_adj: Adjacency matrices for code [batch_size, max_nodes, max_nodes]\n",
    "            code_num_nodes: Number of nodes for each code graph [batch_size]\n",
    "            contrast_seq: Token sequences for contrast [batch_size, max_seq_len]\n",
    "            contrast_adj: Adjacency matrices for contrast [batch_size, max_nodes, max_nodes]\n",
    "            contrast_num_nodes: Number of nodes for each contrast graph [batch_size]\n",
    "        \n",
    "        Returns:\n",
    "            logits: [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # Encode both graphs\n",
    "        code_embedding = self.gnn(code_seq, code_adj, code_num_nodes)\n",
    "        contrast_embedding = self.gnn(contrast_seq, contrast_adj, contrast_num_nodes)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        combined = torch.cat([code_embedding, contrast_embedding], dim=1)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "print(\"GIN Model Architecture defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "vocab_size = embedding_matrix.shape[0]\n",
    "\n",
    "model = SiameseGNN(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_SIZE,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_classes=2,\n",
    "    dropout=0.3,\n",
    "    pretrained_embeddings=embedding_matrix\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nModel initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "print(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc='Training', leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Move data to device\n",
    "        code_graph = batch['code_graph'].to(device)\n",
    "        contrast_graph = batch['contrast_graph'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        code_num_nodes = batch['code_num_nodes']\n",
    "        contrast_num_nodes = batch['contrast_num_nodes']\n",
    "        \n",
    "        code_seq = batch['code_sequence']\n",
    "        contrast_seq = batch['contrast_sequence']\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(\n",
    "            code_seq, code_graph, code_num_nodes,\n",
    "            contrast_seq, contrast_graph, contrast_num_nodes\n",
    "        )\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100 * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation/test set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Evaluating', leave=False):\n",
    "            # Move data to device\n",
    "            code_graph = batch['code_graph'].to(device)\n",
    "            contrast_graph = batch['contrast_graph'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            code_num_nodes = batch['code_num_nodes']\n",
    "            contrast_num_nodes = batch['contrast_num_nodes']\n",
    "            \n",
    "            code_seq = batch['code_sequence']\n",
    "            contrast_seq = batch['contrast_sequence']\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(\n",
    "                code_seq, code_graph, code_num_nodes,\n",
    "                contrast_seq, contrast_graph, contrast_num_nodes\n",
    "            )\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # Probability of class 1\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='binary', zero_division=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy * 100,\n",
    "        'precision': precision * 100,\n",
    "        'recall': recall * 100,\n",
    "        'f1': f1 * 100,\n",
    "        'auc': auc,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "test_f1s = []\n",
    "\n",
    "best_test_f1 = 0\n",
    "best_model_state = None\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_metrics = evaluate(model, test_loader, criterion, device)\n",
    "    test_losses.append(test_metrics['loss'])\n",
    "    test_accs.append(test_metrics['accuracy'])\n",
    "    test_f1s.append(test_metrics['f1'])\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss:  {test_metrics['loss']:.4f} | Test Acc:  {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"Test Precision: {test_metrics['precision']:.2f}% | Test Recall: {test_metrics['recall']:.2f}%\")\n",
    "    print(f\"Test F1: {test_metrics['f1']:.2f}% | Test AUC: {test_metrics['auc']:.4f}\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(test_metrics['f1'])\n",
    "    \n",
    "    # Save best model\n",
    "    if test_metrics['f1'] > best_test_f1:\n",
    "        best_test_f1 = test_metrics['f1']\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"*** New best F1: {best_test_f1:.2f}% ***\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"\\nTraining complete! Best test F1: {best_test_f1:.2f}%\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "torch.save(best_model_state, 'best_model.pth')\n",
    "print(\"Best model saved to 'best_model.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(train_losses, label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(test_losses, label='Test Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Test Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "axes[0, 1].plot(train_accs, label='Train Accuracy', linewidth=2)\n",
    "axes[0, 1].plot(test_accs, label='Test Accuracy', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Training and Test Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# F1 curve\n",
    "axes[1, 0].plot(test_f1s, label='Test F1 Score', linewidth=2, color='green')\n",
    "axes[1, 0].axhline(y=best_test_f1, color='r', linestyle='--', label=f'Best F1: {best_test_f1:.2f}%')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('F1 Score (%)')\n",
    "axes[1, 0].set_title('Test F1 Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Summary statistics\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "Final Training Results\n",
    "{'='*50}\n",
    "\n",
    "Best Test F1 Score: {best_test_f1:.2f}%\n",
    "Final Train Loss: {train_losses[-1]:.4f}\n",
    "Final Test Loss: {test_losses[-1]:.4f}\n",
    "Final Train Accuracy: {train_accs[-1]:.2f}%\n",
    "Final Test Accuracy: {test_accs[-1]:.2f}%\n",
    "\n",
    "Model Configuration:\n",
    "  - Embedding Size: {EMBEDDING_SIZE}\n",
    "  - Hidden Dim: {HIDDEN_DIM}\n",
    "  - GIN Layers: {NUM_LAYERS}\n",
    "  - Batch Size: {BATCH_SIZE}\n",
    "  - Learning Rate: {LEARNING_RATE}\n",
    "  - Total Epochs: {NUM_EPOCHS}\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "                verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation with best model\n",
    "print(\"Evaluating best model on test set...\\n\")\n",
    "final_metrics = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL TEST SET RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy:  {final_metrics['accuracy']:.2f}%\")\n",
    "print(f\"Precision: {final_metrics['precision']:.2f}%\")\n",
    "print(f\"Recall:    {final_metrics['recall']:.2f}%\")\n",
    "print(f\"F1 Score:  {final_metrics['f1']:.2f}%\")\n",
    "print(f\"AUC-ROC:   {final_metrics['auc']:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(final_metrics['labels'], final_metrics['predictions'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['Human', 'LLM'],\n",
    "            yticklabels=['Human', 'LLM'])\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(final_metrics['labels'], final_metrics['probabilities'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {final_metrics[\"auc\"]:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassifications\n",
    "predictions = np.array(final_metrics['predictions'])\n",
    "labels = np.array(final_metrics['labels'])\n",
    "probabilities = np.array(final_metrics['probabilities'])\n",
    "\n",
    "# Find misclassified samples\n",
    "misclassified_idx = np.where(predictions != labels)[0]\n",
    "correct_idx = np.where(predictions == labels)[0]\n",
    "\n",
    "print(f\"Total samples: {len(labels)}\")\n",
    "print(f\"Correctly classified: {len(correct_idx)} ({100*len(correct_idx)/len(labels):.2f}%)\")\n",
    "print(f\"Misclassified: {len(misclassified_idx)} ({100*len(misclassified_idx)/len(labels):.2f}%)\")\n",
    "\n",
    "# Breakdown by class\n",
    "human_misclassified = np.where((predictions != labels) & (labels == 0))[0]\n",
    "llm_misclassified = np.where((predictions != labels) & (labels == 1))[0]\n",
    "\n",
    "print(f\"\\nMisclassified breakdown:\")\n",
    "print(f\"  Human → LLM: {len(human_misclassified)} (false positives)\")\n",
    "print(f\"  LLM → Human: {len(llm_misclassified)} (false negatives)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confidence for correct predictions\n",
    "correct_probs = probabilities[correct_idx]\n",
    "axes[0].hist(correct_probs, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0].axvline(x=0.5, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Predicted Probability (LLM class)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Confidence Distribution - Correct Predictions', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Confidence for misclassified predictions\n",
    "misclassified_probs = probabilities[misclassified_idx]\n",
    "axes[1].hist(misclassified_probs, bins=30, alpha=0.7, color='red', edgecolor='black')\n",
    "axes[1].axvline(x=0.5, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted Probability (LLM class)', fontsize=11)\n",
    "axes[1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1].set_title('Confidence Distribution - Misclassified', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confidence_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Saving and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete model checkpoint\n",
    "checkpoint = {\n",
    "    'model_state_dict': best_model_state,\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': EMBEDDING_SIZE,\n",
    "    'hidden_dim': HIDDEN_DIM,\n",
    "    'num_layers': NUM_LAYERS,\n",
    "    'max_nodes': MAX_NODES,\n",
    "    'best_test_f1': best_test_f1,\n",
    "    'final_metrics': final_metrics,\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'train_accs': train_accs,\n",
    "    'test_accs': test_accs,\n",
    "    'test_f1s': test_f1s\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "print(\"Complete checkpoint saved to 'checkpoint.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results summary\n",
    "results_summary = {\n",
    "    'model_config': {\n",
    "        'embedding_size': EMBEDDING_SIZE,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'num_layers': NUM_LAYERS,\n",
    "        'max_nodes': MAX_NODES,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'num_epochs': NUM_EPOCHS\n",
    "    },\n",
    "    'final_metrics': {\n",
    "        'accuracy': float(final_metrics['accuracy']),\n",
    "        'precision': float(final_metrics['precision']),\n",
    "        'recall': float(final_metrics['recall']),\n",
    "        'f1': float(final_metrics['f1']),\n",
    "        'auc': float(final_metrics['auc'])\n",
    "    },\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'dataset_stats': {\n",
    "        'train_size': len(valid_dataset),\n",
    "        'test_size': len(test_dataset),\n",
    "        'vocab_size': vocab_size\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('results_summary.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"Results summary saved to 'results_summary.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some example predictions\n",
    "num_examples = 5\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(min(num_examples, len(test_dataset))):\n",
    "    sample = test_dataset[i]\n",
    "    \n",
    "    # Prepare inputs\n",
    "    code_graph = sample['code_graph'].unsqueeze(0).to(device)\n",
    "    contrast_graph = sample['contrast_graph'].unsqueeze(0).to(device)\n",
    "    code_seq = [sample['code_sequence']]\n",
    "    contrast_seq = [sample['contrast_sequence']]\n",
    "    code_num_nodes = [sample['code_num_nodes']]\n",
    "    contrast_num_nodes = [sample['contrast_num_nodes']]\n",
    "    \n",
    "    # Get prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(code_seq, code_graph, code_num_nodes,\n",
    "                      contrast_seq, contrast_graph, contrast_num_nodes)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "        confidence = probs[0][pred].item()\n",
    "    \n",
    "    true_label = sample['label'].item()\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Index: {sample['index']}\")\n",
    "    print(f\"  True Label: {true_label} ({'Human' if true_label == 0 else 'LLM'})\")\n",
    "    print(f\"  Predicted: {pred} ({'Human' if pred == 0 else 'LLM'})\")\n",
    "    print(f\"  Confidence: {confidence*100:.2f}%\")\n",
    "    print(f\"  Code nodes: {sample['code_num_nodes']}, Contrast nodes: {sample['contrast_num_nodes']}\")\n",
    "    print(f\"  {'✓ CORRECT' if pred == true_label else '✗ INCORRECT'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS224W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
